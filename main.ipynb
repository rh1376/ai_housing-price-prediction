{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07be2d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ridge Regression Model...\n",
      "{'model__alpha': np.float64(0.002329951810515372)}\n",
      "Tuned RF RMSE: 201,174.41\n",
      "Tuned RF MAE: 113,750.73\n",
      "Tuned RF R²:  0.732\n",
      "Training Ridge Regression Model Finished.\n",
      "Training Decision Tree Model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best params: {'model__min_samples_split': 10, 'model__min_samples_leaf': 5, 'model__max_features': None, 'model__max_depth': 50, 'model__criterion': 'friedman_mse'}\n",
      "Decision Tree RMSE: 229,691.24\n",
      "Decision Tree R²: 0.651\n",
      "Training Decision Tree Model Finished.\n",
      "Training Random Forest Model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Params:\n",
      "{'model__n_estimators': 800, 'model__min_samples_split': 5, 'model__min_samples_leaf': 1, 'model__max_features': 'sqrt', 'model__max_depth': None, 'model__bootstrap': False}\n",
      "Tuned RF RMSE: 209,394.89\n",
      "Tuned RF MAE: 105,645.06\n",
      "Tuned RF R²:  0.710\n",
      "Training Random Forest Model Finished.\n",
      "Training XGBoost Model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Params:\n",
      "{'model__subsample': 0.8, 'model__reg_lambda': 5.0, 'model__reg_alpha': 0.01, 'model__n_estimators': 600, 'model__min_child_weight': 1, 'model__max_depth': 4, 'model__learning_rate': 0.1, 'model__gamma': 0.5, 'model__colsample_bytree': 0.6}\n",
      "Tuned XGBoost RMSE: 203,248.83\n",
      "Tuned XGBoost MAE:  98,023.10\n",
      "Tuned XGBoost R²:   0.727\n",
      "Training XGBoost Model Finished.\n"
     ]
    }
   ],
   "source": [
    "from math import pi\n",
    "import polars as pl\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "set_config(transform_output='polars')\n",
    "\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "current_folder = globals()['_dh'][0]\n",
    "path = current_folder / \"data\" / \"dataset.arff\"\n",
    "\n",
    "data, meta = arff.loadarff(path)\n",
    "df_pd = pd.DataFrame(data)\n",
    "raw = pl.from_pandas(df_pd)\n",
    "raw = raw.with_columns(\n",
    "    pl.col(\"zipcode\").cast(pl.Utf8)\n",
    ")\n",
    "\n",
    "X = raw.drop(\"price\")\n",
    "y = raw[\"price\"].to_numpy()  # 1D array (خیلی مهم)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "class ZipTargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.global_mean_ = np.mean(y)\n",
    "\n",
    "        # mean price per zipcode (برای test / inference)\n",
    "        self.zip_mean_ = (\n",
    "            X.with_columns(pl.Series(\"target\", y))\n",
    "             .group_by(\"zipcode\")\n",
    "             .agg(zip_mean=pl.col(\"target\").mean())\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        with pl.StringCache():\n",
    "            X = X.join(self.zip_mean_, on=\"zipcode\", how=\"left\")\n",
    "\n",
    "        # zipcodeهای دیده‌نشده\n",
    "        X = X.with_columns(\n",
    "            pl.col(\"zip_mean\").fill_null(self.global_mean_)\n",
    "        )\n",
    "\n",
    "        return X\n",
    "\n",
    "numeric_features = [\"bedrooms\", \"bathrooms\", \"sqft_living\"]\n",
    "categorical_features = [\"zipcode\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"Training Ridge Regression Model...\")\n",
    "\n",
    "ridge_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"zip_encoder\", ZipTargetEncoder()),\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", Ridge())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"model__alpha\": np.logspace(-3, 3, 50)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    ridge_pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "best_ridge = search.best_estimator_\n",
    "print(search.best_params_)\n",
    "\n",
    "# 7) ارزیابی روی test\n",
    "pred = best_ridge.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "print(f\"Tuned RF RMSE: {rmse:,.2f}\")\n",
    "print(f\"Tuned RF MAE: {mae:,.2f}\")\n",
    "print(f\"Tuned RF R²:  {r2:.3f}\")\n",
    "\n",
    "# ridge_model = Ridge(alpha=1.0)\n",
    "\n",
    "# ridge_pipe = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"zip_encoder\", ZipTargetEncoder()),\n",
    "#         (\"preprocess\", preprocessor),\n",
    "#         (\"model\", ridge_model),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "# alphas = [0.01, 0.1, 1, 5, 10]\n",
    "\n",
    "# for a in alphas:\n",
    "#     ridge_pipe.set_params(model__alpha=a)\n",
    "#     ridge_pipe.fit(X_train, y_train)\n",
    "#     pred = ridge_pipe.predict(X_test)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "#     mae = mean_absolute_error(y_test, pred)\n",
    "#     print(f\"Alpha: {a}, RMSE: {rmse:.2f} --- MAE: {mae:.2f} --- R²: {ridge_pipe.score(X_test, y_test):.2f}\")\n",
    "\n",
    "print(\"Training Ridge Regression Model Finished.\")\n",
    "\n",
    "print(\"Training Decision Tree Model...\")\n",
    "\n",
    "dt_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"zip_encoder\", ZipTargetEncoder()),\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", DecisionTreeRegressor(random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"model__max_depth\": [None, 5, 10, 20, 30, 50],\n",
    "    \"model__min_samples_split\": [2, 5, 10, 20, 50],\n",
    "    \"model__min_samples_leaf\": [1, 2, 5, 10, 20],\n",
    "    \"model__max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"model__criterion\": [\"squared_error\", \"friedman_mse\"],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=dt_pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "best_dt = search.best_estimator_\n",
    "\n",
    "pred = best_dt.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(f\"Decision Tree RMSE: {rmse:,.2f}\")\n",
    "print(f\"Decision Tree R²: {r2:.3f}\")\n",
    "\n",
    "# dt_model = DecisionTreeRegressor()\n",
    "# dt_pipe = Pipeline(steps=[\n",
    "#                       ('zip_encoder', ZipTargetEncoder()),\n",
    "#                       ('preprocessor', preprocessor),\n",
    "#                       ('dt', dt_model),\n",
    "#                       ])\n",
    "\n",
    "# max_depth = range(1, 20)\n",
    "# for a in max_depth:\n",
    "#     dt_pipe.set_params(dt__max_depth=a)\n",
    "#     dt_pipe.fit(X_train, y_train)\n",
    "#     pred = dt_pipe.predict(X_test)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "#     mae = mean_absolute_error(y_test, pred)\n",
    "#     print(f\"max_depth: {a}, RMSE: {rmse:.2f} --- MAE: {mae:.2f} --- R²: {dt_pipe.score(X_test, y_test):.2f}\")\n",
    "\n",
    "print(\"Training Decision Tree Model Finished.\")\n",
    "\n",
    "print(\"Training Random Forest Model...\")\n",
    "\n",
    "# 1) مدل پایه\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# 2) پایپ‌لاین\n",
    "rf_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"zip_encoder\", ZipTargetEncoder()),\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", rf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 3) فضای جستجو (Hyperparameter Space)\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [200, 400, 600, 800],\n",
    "    \"model__max_depth\": [None, 5, 10, 20, 30, 50],\n",
    "    \"model__min_samples_split\": [2, 5, 10, 20],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4, 8],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"model__bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "# 4) Randomized Search\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=rf_pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,                 # بیشترش بهتر، ولی کندتر\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",  # سازگار با نسخه‌های قدیمی\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5) اجرا\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\")\n",
    "print(search.best_params_)\n",
    "\n",
    "# 6) بهترین مدل\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "# 7) ارزیابی روی test\n",
    "pred = best_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "print(f\"Tuned RF RMSE: {rmse:,.2f}\")\n",
    "print(f\"Tuned RF MAE: {mae:,.2f}\")\n",
    "print(f\"Tuned RF R²:  {r2:.3f}\")\n",
    "\n",
    "\n",
    "print(\"Training Random Forest Model Finished.\")\n",
    "\n",
    "print(\"Training XGBoost Model...\")\n",
    "\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# مدل پایه XGBoost\n",
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\"  # سریع‌تر (روی خیلی از سیستم‌ها بهتره)\n",
    ")\n",
    "\n",
    "xgb_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"zip_encoder\", ZipTargetEncoder()),\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", xgb),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [300, 600, 900, 1200],\n",
    "    \"model__learning_rate\": [0.01, 0.03, 0.05, 0.1, 0.2],\n",
    "    \"model__max_depth\": [3, 4, 5, 6, 8, 10],\n",
    "    \"model__min_child_weight\": [1, 3, 5, 10],\n",
    "    \"model__subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"model__colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"model__gamma\": [0, 0.05, 0.1, 0.2, 0.5],\n",
    "    \"model__reg_alpha\": [0, 0.01, 0.1, 1.0, 10.0],\n",
    "    \"model__reg_lambda\": [0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb_pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,                    # اگر زمان داشتی بکن 50 یا 80\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",  # سازگار با نسخه‌های قدیمی sklearn\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\")\n",
    "print(search.best_params_)\n",
    "\n",
    "best_xgb = search.best_estimator_\n",
    "\n",
    "pred = best_xgb.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "print(f\"Tuned XGBoost RMSE: {rmse:,.2f}\")\n",
    "print(f\"Tuned XGBoost MAE:  {mae:,.2f}\")\n",
    "print(f\"Tuned XGBoost R²:   {r2:.3f}\")\n",
    "\n",
    "print(\"Training XGBoost Model Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
